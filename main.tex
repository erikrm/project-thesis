\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{float}
\usepackage{lscape}

%User defined commands
\newcommand*\mean[1]{\bar{#1}}

\newcommand*\hadamarddiv{\obslash} %Hadamard division

\title{Project-thesis}
\author{Erik Rundhovde M\o renskog}
\date{September 2019}

\begin{document}

\maketitle

\tableofcontents

\section{Abstract}
This thesis will describe how to detect parameters in garbage 

Waste is a huge resource that is in large degrees wasted in todays society. In Norway 39\% is recycled, 57\% is burned for energy (Waste to energy or WtE) and 2\% goes into landfills \cite{EnvironmentGlance20152015} p.50. This thesis will look into one way of analyzing waste before burning. The idea is to use a spectrometer in the visible range combined with a camera to monitor the waste as it is inserted into the waste can. This will allow us to over time find parameters describing the waste, and possibly the objects the waste consists of. 


\section{Introduction}
Hyperspectral imaging is extremely useful for classifying substances from a distance, but it is also very expensive. This paper will study if it is possible to use the much cheaper combination of camera and spectrometer instead of a hyperspectral camera in some situations. 
Hyperspectral imaging is a growing technology for remote sensing. The advantage is that you can get high spectral resolution in  systems are to collect information about materials and objects in a manner similar to hyper-spectral imaging. 

%The setup being proposed in this paper is meant to be a cheaper replacement of the hyper-spectral one.


Spectrometry 
Spectrometer is a widely used tool for analyzing substances. It is a remote sensing tool that give good for



\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/pt_setup.png}
    \caption{Measurement setup}
    \label{}
\end{figure}


\section{Theory}
%Need theory about ccd? It is not really relevant is it?
%Need theory about the different uses of the same sensor in spectrometer and camera


\section{Definitions}

\subsection{Reflection}
Reflection of light describes the notion of light hitting materials and getting a change of path due to the exchange of energy with the material. 

%TODO: Im not sure yet about including these
%\subsubsection{Specular} 
%\subsubsection{Diffusive}
%\subsection{Relative reflection}

\subsection{Image}
Each image will be stored in a matrix where each element of the matrix is a vector described by (\ref{eq:vector_pixel_bgr}). 
\begin{equation}
    \label{eq:vector_pixel_bgr}
    \vec{p}_{ij} = [B,G,R]
\end{equation} 
The vectors describes the color combination of each pixel, where each color blue (B), green (G) and red (R) are unsigned integers. The matrix $A_{N\cdot M}$ is shown in (\ref{eq:image_matrix})

\begin{equation}
    \label{eq:image_matrix}
    A = A_{N\cdot M} =  
    \begin{bmatrix}
        \vec{p}_{11} & \vec{p}_{12} & \cdots & & \vec{p}_{1M}  \\
        \vec{p}_{21} & \ddots &        &       &                \\
        \vdots       &        &\vec{p}_{ij}&   & \vdots          \\
                     &        &        & \ddots&                  \\
        \vec{p}_{N1} &        &        &       & \vec{p}_{NM}  
    \end{bmatrix}
\end{equation}

An important equation later is the to take the spatial average of the matrix, this is done with (\ref{eq:spatial_sum}).

\begin{equation}
    \label{eq:spatial_sum}
    \mean{\vec{p}} = \frac{1}{NM} \sum_{i=0}^{N-1} \sum_{j=0}^{M-1} \vec{p_{ij}}
\end{equation}

Element wise division will be used to compare two pictures, and is defined by the Hadamard division \cite{HadamardDivisionInfixed}:

\begin{equation}
    \label{eq:element_wise_division_image}
    A \oslash  A_0  \frac{A_{ij}}{A_{0ij} } %TODO
\end{equation}


\subsection{Spectrum}
\label{sec:spectrum}

The spectrum read from the spectrometer is saved in a $C x 2$ matrix, where $C$ is the dataset length, the first column is the wavelength ($\lambda$) and the second column is the corresponding intensity (\ref{eq:intensity})
\begin{equation}
    \label{eq:intensity}
    I = I(\lambda)    
\end{equation}

\begin{equation}
    \label{eq:intensity_0_background}
    I_0 = I_0(\lambda)
\end{equation}

We will also define a value (\ref{eq:intensity_0_background}) which is $I$ for the special case where the spectrum is muffin the background spectral response without any objects. From these definitions we define relative reflectance $RR$ (\ref{eq:relative_reflectance}). 

\begin{equation}
    \label{eq:relative_reflectance}
    RR = \frac{I}{I_0}
\end{equation}

The introduction of (\ref{eq:relative_reflectance_minus_one}) will make it easier to compare the spectrum and camera values.  

\begin{equation}
    \label{eq:relative_reflectance_minus_one}
    RR_2 = RR - 1
\end{equation}

We further introduce the notion of finding the spectrum corresponding to one color in the camera. Each pixel in the camera measures the light intensity for blue, green and red with a certain quantum efficiency (\ref{eq:quantum_efficiency}) given by the manufacturer. 

\begin{equation}
    \label{eq:quantum_efficiency}
    QE = QE(\lambda)    
\end{equation}

This value can theoretically be used to relate the relative picture values with the relative reflectance values. This would be a major advantage as it can give us an insight into the noise factor affecting the sensor fusion.  


\section{Method}
The idea is to use spectrometer methods to analyze images, this will open up for the opportunity to pre-process spectral and spatial data in the same way. We will then be able to compare the data directly. The point of this is to emulate a hyperspectral camera. 


\subsection{Correlating Spectrometer to Camera}
\label{sec:method_correlating_spectrum_to_camera}
To get an idea of how well calibrated the camera is to the spectrometer and vice versa I propose the following calculation: 
Take the spatial average across the image from the camera and divide it with the spectral average of the spectrometer. 



\subsection{Light}
Light is a crucial part of this project, as it is the source of input for both the camera and the spectrometer. It's also the link between the two sensors. The choosing of a sensor that can support both sensor types is therefore paramount. 

The characterization of the light source will be based on considerations from \cite{martinPracticalGuideMachine}, but also unfortunately be limited by available sources at the lab. This paper provides a longer checklist, that can be simplified greatly under the following conditions: Stationary objects,





\section{Results}

The photos and spectrums where taken inside a lab with no external lights, and the real setup is as shown in figure \ref{fig:picture_of_setup_unlit}. %TODO: Change this figure into the side by side, lit - unlit


\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/picture_taking_in_the_dark}
    \caption{Photo of the setup unlit}
    \label{fig:picture_of_setup_unlit}
\end{figure}


\subsection{Spetrum of camera}
Figure \ref{fig:relative_reflection_around_zero} shows nine plots, the first one shows the reference spectrum, the spectrum without any objects. The following eight plots shows the Relative Reflectance (\ref{eq:relative_reflectance}), their 

\begin{landscape}
\begin{figure}[t]
    \centering
    \includegraphics[width=1\paperwidth]{Plots/relative_reflectance_around_zero_with_qe_color_response.png}
    \caption{Relative reflection centered around zero}
    \label{fig:relative_reflection_around_zero}
\end{figure}
\end{landscape}


\subsection{Correlating Spectrometer to Camera}


\section{Conclusion}

It has proven very hard to correlate spectrometer and camera values that should be similar, even in ideal situations as in a dark lab.

\bibliographystyle{plain}
\bibliography{references.bib}
\end{document}